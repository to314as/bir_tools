{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/mnt/mnt/5TB_slot2/Tobias')\n",
    "sys.path.append('/mnt/mnt/5TB_slot2/Tobias/TobiasPy/fastMRI')\n",
    "sys.path.append('/mnt/mnt/4TB_pcie/fastBrain/')\n",
    "import h5py\n",
    "import numpy as np\n",
    "import numpy.fft as nf\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from models.unet.unet_model import UnetModel as UnetModel\n",
    "from FF_net import FF_net\n",
    "from FF_net import FF_simple_net\n",
    "from FF_net import FF_net_tanh\n",
    "from FF_net import Complex_net\n",
    "import argparse\n",
    "from common.args import Args\n",
    "import models.unet.run_unet  as Run\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "import pathlib\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "import time\n",
    "from torch.nn import functional as F\n",
    "import shutil\n",
    "from tensorboardX import SummaryWriter\n",
    "import torchvision\n",
    "from torchvision import transforms, utils\n",
    "import net_utils as nu\n",
    "import calendar\n",
    "import datetime\n",
    "from longOne import ComplexFourier,ComplexEndToEnd\n",
    "from complex_unet_model import ComplexUnetModel\n",
    "\n",
    "import sigpy as sp\n",
    "import sigpy.plot as pl\n",
    "import vd_spiral\n",
    "\n",
    "from FF_net import Complex_net_ext\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save to /mnt/mnt/5TB_slot2/Tobias/Thesis/FF_lrelu_ComplexEndToEnd_ComplexU/best_model.pt\n"
     ]
    }
   ],
   "source": [
    "sys.argv=['']\n",
    "def create_arg_parser():\n",
    "    timestamp = calendar.timegm(time.gmtime())\n",
    "    human_readable = datetime.datetime.fromtimestamp(timestamp).isoformat()\n",
    "    #human_readable=\"pure_inverse_fourier\"\n",
    "    human_readable=\"ComplexEndToEnd_ComplexU\"\n",
    "    parser = argparse.ArgumentParser(description=\"ML parameters\")\n",
    "    parser.add_argument('--num-pools', type=int, default=4, help='Number of U-Net pooling layers')\n",
    "    parser.add_argument('--drop-prob', type=float, default=0.0, help='Dropout probability')\n",
    "    parser.add_argument('--num-chans', type=int, default=32, help='Number of U-Net channels')\n",
    "\n",
    "    parser.add_argument('--batch-size', default=16, type=int, help='Mini batch size')\n",
    "    parser.add_argument('--num-epochs', type=int, default=250, help='Number of training epochs')\n",
    "    parser.add_argument('--lr', type=float, default=0.0001, help='Learning rate')\n",
    "    parser.add_argument('--lr-step-size', type=int, default=100,\n",
    "                        help='Period of learning rate decay')\n",
    "    parser.add_argument('--lr-gamma', type=float, default=0.1,\n",
    "                        help='Multiplicative factor of learning rate decay')\n",
    "    parser.add_argument('--weight-decay', type=float, default=0.01,\n",
    "                        help='Strength of weight decay regularization')\n",
    "    parser.add_argument('--momentum', type=float, default=0.1,\n",
    "                        help='Strength of optimizer momentum')\n",
    "\n",
    "    parser.add_argument('--report-interval', type=int, default=10000, help='Period of loss reporting')\n",
    "    parser.add_argument('--data-parallel', default=True,\n",
    "                        help='If set, use multiple GPUs using data parallelism')\n",
    "    parser.add_argument('--device', type=str, default='cuda',\n",
    "                        help='Which device to train on. Set to \"cuda\" to use the GPU')\n",
    "    parser.add_argument('--exp-dir', type=pathlib.Path, default='/mnt/mnt/5TB_slot2/Tobias/Thesis/FF_lrelu_'+str(human_readable),\n",
    "                        help='Path where model and results should be saved')\n",
    "    parser.add_argument('--resume', action='store_true', default=False,\n",
    "                        help='If set, resume the training from a previous model checkpoint. '\n",
    "                             '\"--checkpoint\" should be set with this')\n",
    "    parser.add_argument('--checkpoint', type=str, default='/mnt/mnt/5TB_slot2/Tobias/Thesis/FF_lrelu_'+str(human_readable)+'/best_model.pt',\n",
    "                        help='Path to an existing checkpoint. Used along with \"--resume\"')\n",
    "    parser.add_argument('--logdir', type=str, default='/mnt/mnt/5TB_slot2/Tobias/Thesis/log/ff_lrelu_'+str(human_readable),\n",
    "                        help='Path to an existing checkpoint. Used along with \"--resume\"')\n",
    "    parser.add_argument('--seed', default=42, type=int, help='Seed for random number generators')\n",
    "    parser.add_argument('--resolution', default=256, type=int, help='Resolution of images')\n",
    "    parser.add_argument('--device_ids', default=[2,3] , help='GPUS used')\n",
    "    return parser\n",
    "args=create_arg_parser().parse_args()\n",
    "print(\"save to\",args.checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fourier():\n",
    "    sig = np.random.randn(args.resolution) + 1j*np.random.randn(320)\n",
    "    F = np.fft.ifft(sig, axis=-1)\n",
    "    # First half of inputs/outputs is real part, second half is imaginary part\n",
    "    X = torch.from_numpy(np.hstack([sig.real, sig.imag])).double()\n",
    "    Y = torch.from_numpy((F.real**2+F.imag**2)**(1/2)).double()\n",
    "    return X,Y\n",
    "\n",
    "class SliceData(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset that provides access to MR image slices.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, root=\"/mnt/mnt/5TB_slot2/fastMRI/multicoil_train\", sample_rate=1.):\n",
    "        self.examples = []\n",
    "        #potential to apply pre-process transform\n",
    "        files = list(pathlib.Path(root).iterdir())\n",
    "        if sample_rate < 1:\n",
    "            #random.shuffle(files)\n",
    "            num_files = round(len(files) * sample_rate)\n",
    "            files = files[:num_files]\n",
    "        for fname in sorted(files):\n",
    "            print(fname)\n",
    "            try:\n",
    "                #print(h5py.File(fname, 'r').keys())\n",
    "                #maybe also only randomly select parts of slices. Otherwise lot of outer noise-like structures.\n",
    "                xml = h5py.File(fname, 'r')['ismrmrd_header']\n",
    "                kspace = h5py.File(fname, 'r')['kspace']\n",
    "                num_slices = kspace.shape[0]\n",
    "                num_channels=kspace.shape[1]\n",
    "                if (kspace.shape[-2]<args.resolution) or (kspace.shape[-1]<args.resolution):# or num_channels!=16:\n",
    "                    continue\n",
    "                print(len(self.examples))\n",
    "                for slice in range(num_slices):\n",
    "                    crop_size = (min(args.resolution, kspace.shape[-2]),min(args.resolution, kspace.shape[-1]))\n",
    "                    k=nu.center_crop(kspace[slice], crop_size)[0]\n",
    "                    target=abs(nu.make_ift(k))\n",
    "                    m=np.max(target)\n",
    "                    if m>0:\n",
    "                        target/=m\n",
    "                    else:\n",
    "                        continue\n",
    "                    k=nu.to_tensor(k).unsqueeze(0)\n",
    "                    us=nu.apply_mask(k)[0]#*args.resolution\n",
    "                    us/=m\n",
    "                    if np.isnan(np.sum(target)):\n",
    "                        continue\n",
    "                    X=us#.flatten()\n",
    "                    print(X.shape)\n",
    "                    #print(X.shape)\n",
    "                    Y=nu.to_tensor(target)\n",
    "                    #print(Y.shape)\n",
    "                    #X,Y=test_fourier()\n",
    "                    self.examples += [(fname, slice, X, Y)]\n",
    "            except:\n",
    "                print(\"Couldn't open file\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        fname, slice, f, t = self.examples[i]\n",
    "#         with h5py.File(fname, 'r') as data:\n",
    "#             full=to_tensor(data['kspace'][slice])\n",
    "#             crop_size = (min(args.resolution, full.shape[-3]),min(args.resolution, full.shape[-2]))          \n",
    "#             full=complex_center_crop(full,crop_size)\n",
    "            \n",
    "#             kspace = to_tensor(data['kspace'][slice])\n",
    "#             crop_size = (min(args.resolution, kspace.shape[-3]), min(args.resolution, kspace.shape[-2]))\n",
    "#             kspace=apply_mask(kspace)[0]\n",
    "#             kspace = complex_center_crop(kspace, crop_size)\n",
    "            \n",
    "        return (f, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loaders():\n",
    "    #batch_size=32\n",
    "    #mask_func = None\n",
    "    #if args.mask_kspace:\n",
    "    #    mask_func = MaskFunc(args.center_fractions, args.accelerations)\n",
    "    train_data = SliceData(root=\"/mnt/mnt/4TB_pcie/fastBrain/multicoil_train\",sample_rate=0.05)\n",
    "    dev_data = SliceData(root=\"/mnt/mnt/4TB_pcie/fastBrain/multicoil_test_brain\",sample_rate=0.05)\n",
    "    test_data = SliceData(root=\"/mnt/mnt/4TB_pcie/fastBrain/multicoil_test_brain\",sample_rate=0.05)\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_data,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    dev_loader = DataLoader(\n",
    "        dataset=dev_data,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    test_loader=None\n",
    "#     test_loader = DataLoader(\n",
    "#         dataset=test_data,\n",
    "#         num_workers=0,\n",
    "#         pin_memory=True,\n",
    "#     )\n",
    "    return train_loader, dev_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/mnt/4TB_pcie/fastBrain/multicoil_train/file_brain_AXFLAIR_200_6002496.h5\n",
      "0\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "/mnt/mnt/4TB_pcie/fastBrain/multicoil_train/file_brain_AXFLAIR_200_6002506.h5\n",
      "16\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "/mnt/mnt/4TB_pcie/fastBrain/multicoil_train/file_brain_AXFLAIR_200_6002553.h5\n",
      "32\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "torch.Size([1, 256, 256, 2])\n",
      "/mnt/mnt/4TB_pcie/fastBrain/multicoil_train/file_brain_AXFLAIR_200_6002570.h5\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "t=time.time()\n",
    "train_loader, dev_loader, test_loader= create_data_loaders()\n",
    "print(\"Time taken to load data: \",time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "        for (f, t) in train_loader:\n",
    "            print(f.shape,t.shape)\n",
    "            plt.imshow(abs(nu.make_ift(nu.to_complex(f)))[0,0,:,:])\n",
    "            plt.show()\n",
    "            plt.imshow(t[0,:,:])\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(args,chans=args.num_chans,num_pool_layers=args.num_pools,drop_prob=0.05):\n",
    "    #check every time which gpus are available!\n",
    "    #device_ids=[2,3,1]\n",
    "    device_ids=args.device_ids\n",
    "    model=ComplexUnetModel(in_chans=1,out_chans=1,chans=args.num_chans,num_pool_layers=args.num_pools,drop_prob=args.drop_prob).to(args.device)\n",
    "    model=model.double()\n",
    "    if args.data_parallel and args.device==\"cuda\":\n",
    "        model = nn.DataParallel(model,device_ids=device_ids)\n",
    "    print(\"Model build successfully\")\n",
    "    #vis_weights(model)\n",
    "    return model\n",
    "\n",
    "def vis_weights(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(name, param.data)\n",
    "            # Heat map of neuron weights\n",
    "            plt.imshow(param.data.cpu(), vmin=np.min(param.data.cpu().numpy()), vmax=np.max(param.data.cpu().numpy()), cmap='coolwarm')\n",
    "            plt.show()\n",
    "#            fig,ax=plt.subplots(320,1,figsize=(16,16))\n",
    "#             for i in range(320):\n",
    "#                 ax[i].plot(param.data.cpu()[i,:320])\n",
    "#             plt.show()\n",
    "\n",
    "def build_optim(args,params):\n",
    "    optimizer = torch.optim.Adadelta(params)\n",
    "    return optimizer\n",
    "\n",
    "def load_model(checkpoint_file,args):\n",
    "    checkpoint = torch.load(checkpoint_file)\n",
    "    args = checkpoint['args']\n",
    "    model = build_model(args)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "    optimizer = build_optim(args, model.parameters())\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    print(\"Model load successfully\")\n",
    "    return checkpoint, model, optimizer\n",
    "\n",
    "def save_model(args, exp_dir, epoch, model, optimizer, best_dev_loss, is_new_best):\n",
    "    torch.save(\n",
    "        {\n",
    "            'epoch': epoch,\n",
    "            'args': args,\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'best_dev_loss': best_dev_loss,\n",
    "            'exp_dir': exp_dir\n",
    "        },\n",
    "        f=exp_dir / 'model.pt'\n",
    "    )\n",
    "    if is_new_best:\n",
    "        shutil.copyfile(exp_dir / 'model.pt', exp_dir / 'best_model.pt')\n",
    "        \n",
    "def visualize(args, epoch, model, data_loader, writer):\n",
    "    def save_image(image, tag):\n",
    "        image -= image.min()\n",
    "        image /= image.max()\n",
    "        grid = torchvision.utils.make_grid(image, nrow=4, pad_value=1)\n",
    "        writer.add_image(tag, grid, epoch)\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for iter, data in enumerate(data_loader):\n",
    "            input, target = data\n",
    "            input = input.unsqueeze(1).to(f'{args.device}:{args.device_ids[0]}')\n",
    "            target = target.unsqueeze(1).to(f'{args.device}:{args.device_ids[0]}')\n",
    "            output = model(input)\n",
    "            save_image(target[0,:,:], 'Target')\n",
    "            save_image(output[0,:,:], 'Reconstruction')\n",
    "            save_image(torch.abs(target - output)[0,:,:], 'Error')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(args, epoch, model, data_loader, optimizer, writer):\n",
    "    model.train()\n",
    "    avg_loss = 0.\n",
    "    start_epoch = start_iter = time.perf_counter()\n",
    "    global_step = epoch * len(data_loader)\n",
    "    for iter, data in enumerate(data_loader):\n",
    "        f, t = data\n",
    "        input = f.to(f'{args.device}:{model.device_ids[0]}')\n",
    "        target = t.to(f'{args.device}:{model.device_ids[0]}')\n",
    "        output = model(input).squeeze(1)\n",
    "        \n",
    "        loss = F.mse_loss(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_loss = 0.99 * avg_loss + 0.01 * loss.item() if iter > 0 else loss.item()\n",
    "        writer.add_scalar('TrainLoss', loss.item(), global_step + iter)\n",
    "\n",
    "#         if iter % args.report_interval == 0:\n",
    "#             print(f'Epoch = [{epoch:3d}/{args.num_epochs:3d}] ',\n",
    "#                 f'Iter = [{iter:4d}/{len(data_loader):4d}] ',\n",
    "#                 f'Loss = {loss.item():.4g} Avg Loss = {avg_loss:.4g} ',\n",
    "#                 f'Time = {time.perf_counter() - start_iter:.4f}s')\n",
    "#             logging.info(\n",
    "#                 f'Epoch = [{epoch:3d}/{args.num_epochs:3d}] '\n",
    "#                 f'Iter = [{iter:4d}/{len(data_loader):4d}] '\n",
    "#                 f'Loss = {loss.item():.4g} Avg Loss = {avg_loss:.4g} '\n",
    "#                 f'Time = {time.perf_counter() - start_iter:.4f}s',\n",
    "#             )\n",
    "        start_iter = time.perf_counter()\n",
    "    return avg_loss, time.perf_counter() - start_epoch\n",
    "\n",
    "def evaluate(args, epoch, model, data_loader, writer):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    start = time.perf_counter()\n",
    "    with torch.no_grad():\n",
    "        for iter, data in enumerate(data_loader):\n",
    "            f, t = data\n",
    "            input = f.to(f'{args.device}:{model.device_ids[0]}')\n",
    "            target = t.to(f'{args.device}:{model.device_ids[0]}')\n",
    "            output = model(input).squeeze(1)\n",
    "\n",
    "            #mean = mean.unsqueeze(1).unsqueeze(2).to(args.device)\n",
    "            #std = std.unsqueeze(1).unsqueeze(2).to(args.device)\n",
    "            #target = target * std + mean\n",
    "            #output = output * std + mean\n",
    "\n",
    "            #norm = norm.unsqueeze(1).unsqueeze(2).to(args.device)\n",
    "            #loss = F.mse_loss(output / norm, target / norm, size_average=False)\n",
    "            loss = F.mse_loss(output, target)\n",
    "            losses.append(loss.item())\n",
    "        writer.add_scalar('Dev_Loss', np.mean(losses), epoch)\n",
    "        print('Dev_Loss', np.mean(losses),'Epoch', epoch)\n",
    "    return np.mean(losses), time.perf_counter() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(args): \n",
    "    args.exp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    writer = SummaryWriter(logdir=str(args.logdir)) #log directory for run\n",
    "\n",
    "    if args.resume: #be aware of the option\n",
    "        checkpoint, model, optimizer = load_model(args.checkpoint,args)\n",
    "        args = checkpoint['args']\n",
    "        best_dev_loss = checkpoint['best_dev_loss']\n",
    "        #start_epoch = checkpoint['epoch']\n",
    "        start_epoch = 0\n",
    "        del checkpoint\n",
    "    else:\n",
    "        model = build_model(args)\n",
    "        optimizer = build_optim(args, model.parameters())\n",
    "        best_dev_loss = 1e9\n",
    "        start_epoch = 0\n",
    "    logging.info(args)\n",
    "    logging.info(model)\n",
    "\n",
    "    #train_loader,dev_loader,test_loader = create_data_loaders()\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, args.lr_step_size, args.lr_gamma)\n",
    "    optimizer.step()\n",
    "\n",
    "    for epoch in range(start_epoch, args.num_epochs):\n",
    "        ti=time.time()\n",
    "        scheduler.step(epoch)\n",
    "        train_loss, train_time = train_epoch(args, epoch, model, train_loader, optimizer, writer)\n",
    "        dev_loss, dev_time = evaluate(args, epoch, model, dev_loader, writer)\n",
    "        #visualize(args, epoch, model, train_loader, writer)\n",
    "\n",
    "        is_new_best = dev_loss < best_dev_loss\n",
    "        best_dev_loss = min(best_dev_loss, dev_loss)\n",
    "        save_model(args, args.exp_dir, epoch, model, optimizer, best_dev_loss, is_new_best)\n",
    "        print(f'Epoch = [{epoch:4d}/{args.num_epochs:4d}] TrainLoss = {train_loss:.4g} ',\n",
    "        f'DevLoss = {dev_loss:.4g} TrainTime = {train_time:.4f}s DevTime = {dev_time:.4f}s')\n",
    "        \n",
    "        for iter, data in enumerate(train_loader):\n",
    "            kspace, full = data\n",
    "            input = kspace.to(f'{args.device}:{model.device_ids[0]}')\n",
    "            target = full.to(f'{args.device}:{model.device_ids[0]}')\n",
    "            output = model(input).squeeze(1)\n",
    "            #print(output)\n",
    "            image=output.to('cpu').detach().numpy()\n",
    "            plt.imshow(image[0,:,:])\n",
    "            plt.show()\n",
    "            plt.imshow(target[0,:,:].to('cpu').detach().numpy())\n",
    "            plt.show()\n",
    "            break;\n",
    "        \n",
    "        logging.info(\n",
    "            f'Epoch = [{epoch:4d}/{args.num_epochs:4d}] TrainLoss = {train_loss:.4g} '\n",
    "            f'DevLoss = {dev_loss:.4g} TrainTime = {train_time:.4f}s DevTime = {dev_time:.4f}s',\n",
    "        )\n",
    "        print(\"Time taken for epoch: \",time.time()-ti)\n",
    "    writer.close()\n",
    "    return dev_loss\n",
    "    \n",
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f =\"/mnt/mnt/5TB_slot2/Tobias/Thesis/FF_lrelue_2020/best_model.pt\"\n",
    "checkpoint, model, optimizer = load_model(args.checkpoint,args)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "        #plt.imshow(nf.ifftshift(param.data.cpu()[:,0,0,:]), vmin=-1, vmax=1, cmap='coolwarm')\n",
    "        # Heat map of neuron weights\n",
    "        weights=nf.ifftshift(param.data.cpu()[:,0,0,:])\n",
    "        plt.imshow(weights, vmin=np.min(param.data.cpu().numpy()), vmax=np.max(param.data.cpu().numpy()), cmap='coolwarm')\n",
    "        plt.show()\n",
    "        fig,ax=plt.subplots(args.resolution//10,1,figsize=(16,16))\n",
    "        for i in range(args.resolution//10):\n",
    "            ax[i].plot(weights[i,:args.resolution])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_plain(args): \n",
    "    args.exp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    writer = SummaryWriter(logdir=str(args.logdir)) #log directory for run\n",
    "    if args.resume: #be aware of the option\n",
    "        checkpoint, model, optimizer = load_model(args.checkpoint,args)\n",
    "        args = checkpoint['args']\n",
    "        best_dev_loss = checkpoint['best_dev_loss']\n",
    "        #start_epoch = checkpoint['epoch']\n",
    "        start_epoch = 0\n",
    "        del checkpoint\n",
    "    else:\n",
    "        model = build_model(args)\n",
    "        optimizer = build_optim(args, model.parameters())\n",
    "        best_dev_loss = 1e9\n",
    "        start_epoch = 0\n",
    "    #train_loader,dev_loader,test_loader = create_data_loaders()\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, args.lr_step_size, args.lr_gamma)\n",
    "    optimizer.step()\n",
    "\n",
    "    for epoch in range(start_epoch, args.num_epochs):\n",
    "        ti=time.time()\n",
    "        scheduler.step(epoch)\n",
    "        train_loss, train_time = train_epoch(args, epoch, model, train_loader, optimizer, writer)\n",
    "        dev_loss, dev_time = evaluate(args, epoch, model, dev_loader, writer)\n",
    "        #visualize(args, epoch, model, train_loader, writer)\n",
    "\n",
    "#         is_new_best = dev_loss < best_dev_loss\n",
    "#         best_dev_loss = min(best_dev_loss, dev_loss)\n",
    "#         save_model(args, args.exp_dir, epoch, model, optimizer, best_dev_loss, is_new_best)\n",
    "    writer.close()\n",
    "    return dev_loss\n",
    "\n",
    "def run_model(lr):\n",
    "    print(lr)\n",
    "    args.lr=lr\n",
    "    return train_plain(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, tpe, fmin\n",
    "\n",
    "# Single line bayesian optimization of polynomial function\n",
    "args.num_epochs=100\n",
    "best = fmin(fn=lambda x: run_model(x),\n",
    "            space=hp.normal('x', 0.0001, 0.5),\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=args.checkpoint#\"/mnt/mnt/5TB_slot2/Tobias/Thesis/FF_lrelu_pure_inverse_fourier/best_model.pt\n",
    "c='/mnt/mnt/5TB_slot2/Tobias/Thesis/FF_lrelu_ComplexEndToEnd'+'/model.pt'\n",
    "checkpoint, model, optimizer = load_model(c,args)\n",
    "model.eval()\n",
    "for iter, data in enumerate(train_loader):\n",
    "            f, t = data\n",
    "            plt.hist(f[abs(f) >= 0.00001].flatten(),bins=1000)\n",
    "            plt.show()\n",
    "            plt.imshow(abs(nu.make_ift(nu.to_complex(f)))[0,0,:,:])\n",
    "            plt.show()\n",
    "            input = f.to(f'{args.device}:{model.device_ids[0]}')\n",
    "            target = t.to(f'{args.device}:{model.device_ids[0]}')\n",
    "            output = model(input).squeeze(1)\n",
    "            #print(output)\n",
    "            image=output.to('cpu').detach().numpy()\n",
    "            plt.imshow(image[0,:,:])\n",
    "            plt.show()\n",
    "            plt.imshow(target[0,:,:].to('cpu').detach().numpy())\n",
    "            plt.show()\n",
    "            #break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
